{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import scipy\n",
    "\n",
    "import math\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1185</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  user_id  rating\n",
       "0        1      314       5\n",
       "1        1      439       3\n",
       "2        1      588       5\n",
       "3        1     1169       4\n",
       "4        1     1185       4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df = pd.read_csv('./book-data/ratings.csv', header = 0)\n",
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>best_book_id</th>\n",
       "      <th>work_id</th>\n",
       "      <th>books_count</th>\n",
       "      <th>isbn</th>\n",
       "      <th>isbn13</th>\n",
       "      <th>authors</th>\n",
       "      <th>original_publication_year</th>\n",
       "      <th>original_title</th>\n",
       "      <th>...</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>work_ratings_count</th>\n",
       "      <th>work_text_reviews_count</th>\n",
       "      <th>ratings_1</th>\n",
       "      <th>ratings_2</th>\n",
       "      <th>ratings_3</th>\n",
       "      <th>ratings_4</th>\n",
       "      <th>ratings_5</th>\n",
       "      <th>image_url</th>\n",
       "      <th>small_image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2767052</td>\n",
       "      <td>2792775</td>\n",
       "      <td>272</td>\n",
       "      <td>439023483</td>\n",
       "      <td>9.780439e+12</td>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>The Hunger Games</td>\n",
       "      <td>...</td>\n",
       "      <td>4780653</td>\n",
       "      <td>4942365</td>\n",
       "      <td>155254</td>\n",
       "      <td>66715</td>\n",
       "      <td>127936</td>\n",
       "      <td>560092</td>\n",
       "      <td>1481305</td>\n",
       "      <td>2706317</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1447303603s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4640799</td>\n",
       "      <td>491</td>\n",
       "      <td>439554934</td>\n",
       "      <td>9.780440e+12</td>\n",
       "      <td>J.K. Rowling, Mary GrandPré</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>...</td>\n",
       "      <td>4602479</td>\n",
       "      <td>4800065</td>\n",
       "      <td>75867</td>\n",
       "      <td>75504</td>\n",
       "      <td>101676</td>\n",
       "      <td>455024</td>\n",
       "      <td>1156318</td>\n",
       "      <td>3011543</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1474154022s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>41865</td>\n",
       "      <td>41865</td>\n",
       "      <td>3212258</td>\n",
       "      <td>226</td>\n",
       "      <td>316015849</td>\n",
       "      <td>9.780316e+12</td>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>...</td>\n",
       "      <td>3866839</td>\n",
       "      <td>3916824</td>\n",
       "      <td>95009</td>\n",
       "      <td>456191</td>\n",
       "      <td>436802</td>\n",
       "      <td>793319</td>\n",
       "      <td>875073</td>\n",
       "      <td>1355439</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361039443s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2657</td>\n",
       "      <td>2657</td>\n",
       "      <td>3275794</td>\n",
       "      <td>487</td>\n",
       "      <td>61120081</td>\n",
       "      <td>9.780061e+12</td>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>To Kill a Mockingbird</td>\n",
       "      <td>...</td>\n",
       "      <td>3198671</td>\n",
       "      <td>3340896</td>\n",
       "      <td>72586</td>\n",
       "      <td>60427</td>\n",
       "      <td>117415</td>\n",
       "      <td>446835</td>\n",
       "      <td>1001952</td>\n",
       "      <td>1714267</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1361975680s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4671</td>\n",
       "      <td>4671</td>\n",
       "      <td>245494</td>\n",
       "      <td>1356</td>\n",
       "      <td>743273567</td>\n",
       "      <td>9.780743e+12</td>\n",
       "      <td>F. Scott Fitzgerald</td>\n",
       "      <td>1925.0</td>\n",
       "      <td>The Great Gatsby</td>\n",
       "      <td>...</td>\n",
       "      <td>2683664</td>\n",
       "      <td>2773745</td>\n",
       "      <td>51992</td>\n",
       "      <td>86236</td>\n",
       "      <td>197621</td>\n",
       "      <td>606158</td>\n",
       "      <td>936012</td>\n",
       "      <td>947718</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560m...</td>\n",
       "      <td>https://images.gr-assets.com/books/1490528560s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  book_id  best_book_id  work_id  books_count       isbn        isbn13  \\\n",
       "0   1  2767052       2767052  2792775          272  439023483  9.780439e+12   \n",
       "1   2        3             3  4640799          491  439554934  9.780440e+12   \n",
       "2   3    41865         41865  3212258          226  316015849  9.780316e+12   \n",
       "3   4     2657          2657  3275794          487   61120081  9.780061e+12   \n",
       "4   5     4671          4671   245494         1356  743273567  9.780743e+12   \n",
       "\n",
       "                       authors  original_publication_year  \\\n",
       "0              Suzanne Collins                     2008.0   \n",
       "1  J.K. Rowling, Mary GrandPré                     1997.0   \n",
       "2              Stephenie Meyer                     2005.0   \n",
       "3                   Harper Lee                     1960.0   \n",
       "4          F. Scott Fitzgerald                     1925.0   \n",
       "\n",
       "                             original_title  ... ratings_count  \\\n",
       "0                          The Hunger Games  ...       4780653   \n",
       "1  Harry Potter and the Philosopher's Stone  ...       4602479   \n",
       "2                                  Twilight  ...       3866839   \n",
       "3                     To Kill a Mockingbird  ...       3198671   \n",
       "4                          The Great Gatsby  ...       2683664   \n",
       "\n",
       "  work_ratings_count  work_text_reviews_count  ratings_1  ratings_2  \\\n",
       "0            4942365                   155254      66715     127936   \n",
       "1            4800065                    75867      75504     101676   \n",
       "2            3916824                    95009     456191     436802   \n",
       "3            3340896                    72586      60427     117415   \n",
       "4            2773745                    51992      86236     197621   \n",
       "\n",
       "   ratings_3  ratings_4  ratings_5  \\\n",
       "0     560092    1481305    2706317   \n",
       "1     455024    1156318    3011543   \n",
       "2     793319     875073    1355439   \n",
       "3     446835    1001952    1714267   \n",
       "4     606158     936012     947718   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  https://images.gr-assets.com/books/1447303603m...   \n",
       "1  https://images.gr-assets.com/books/1474154022m...   \n",
       "2  https://images.gr-assets.com/books/1361039443m...   \n",
       "3  https://images.gr-assets.com/books/1361975680m...   \n",
       "4  https://images.gr-assets.com/books/1490528560m...   \n",
       "\n",
       "                                     small_image_url  \n",
       "0  https://images.gr-assets.com/books/1447303603s...  \n",
       "1  https://images.gr-assets.com/books/1474154022s...  \n",
       "2  https://images.gr-assets.com/books/1361039443s...  \n",
       "3  https://images.gr-assets.com/books/1361975680s...  \n",
       "4  https://images.gr-assets.com/books/1490528560s...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df = pd.read_csv('./book-data/books.csv', header = 0)\n",
    "books_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981756, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df = pd.read_csv('./book-data/books.csv', header = 0)\n",
    "books_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, user_item_pairs, ratings):\n",
    "        'Initialization'\n",
    "        self.labels  = ratings\n",
    "        self.samples = user_item_pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # # Load data and get label\n",
    "        #print(\"called get item\")\n",
    "        user_item_pair = self.samples[index].astype('long')\n",
    "        user_social = np.zeros(64).astype('long') #convert to actual social embeddings later\n",
    "        user_item_pair_social = np.concatenate((user_item_pair, user_social), axis=None)\n",
    "        X = user_item_pair_social\n",
    "        y = self.labels[index]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_rating(df,count):\n",
    "    user_rating_count = df.groupby('user_id')['user_id'].agg(['count']).reset_index()\n",
    "    cdf = df.merge(user_rating_count, on='user_id')\n",
    "    cdf = cdf[cdf['count']>count][['user_id','book_id','rating']]\n",
    "    user_bias = cdf['user_id'].min()\n",
    "    cdf[['user_id']] -user_bias\n",
    "    # num_users = len(user_rating_count)\n",
    "    \n",
    "    num_users = int(cdf['user_id'].max() - cdf['user_id'].min() + 1)\n",
    "    num_items = int(cdf['book_id'].max() - cdf['book_id'].min() + 1)\n",
    "    \n",
    "    total_ratings = np.array(cdf.values)\n",
    "    total_ratings[:,0:1]-= cdf['user_id'].min()\n",
    "    user_item_pairs = total_ratings[:,0:2]\n",
    "    ratings = total_ratings[:,2:3]\n",
    "    dataset = Dataset(user_item_pairs,ratings)\n",
    "    \n",
    "    return {\"rating_df\":cdf,\"dataset\":dataset ,\"num_users\":num_users,\"num_items\":num_items,\"user_bias\":user_bias}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "\n",
    "## Generalized Matrix Factorization \n",
    "\n",
    "An abstrsct of traditional MF method, the products of embeding layout are ratings of user give to each item\n",
    "if only use one dimention it will be traditional MF, but the neural network has expand that structure, and allows it can catch the features that traditional MF model can't catchs.\n",
    "\n",
    "element-wise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_items,latent_dim=8):\n",
    "        super(MF, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.embedding_user = torch.nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.latent_dim,sparse=True)\n",
    "        self.embedding_item = torch.nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.latent_dim,sparse=True)\n",
    "        self.fc = nn.Linear(in_features=self.latent_dim, out_features=1, bias=True)\n",
    "        \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = F.relu(self.embedding_user(user_indices))\n",
    "        item_embedding = F.relu(self.embedding_item(item_indices))\n",
    "        return F.relu(self.fc(user_embedding * item_embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron \n",
    "\n",
    "concatenation\n",
    "\n",
    "The GMF only use one layer, but MLP use multi-layout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_items,latent_dim=8,layers = [16,32,16,8]):\n",
    "        super(MLP, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self.embedding_user = torch.nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.latent_dim,sparse=True)\n",
    "        self.embedding_item = torch.nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.latent_dim,sparse=True)\n",
    "\n",
    "        self.fc_layers = torch.nn.ModuleList()\n",
    "        for idx, (in_size, out_size) in enumerate(zip(layers[:-1], layers[1:])):\n",
    "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "\n",
    "        self.affine_output = torch.nn.Linear(in_features=layers[-1], out_features=1)\n",
    "#         self.logistic = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "#         print(\"item_embedding\")\n",
    "        user_embedding = self.embedding_user(user_indices)\n",
    "        item_embedding = self.embedding_item(item_indices)\n",
    "        \n",
    "        vector = torch.cat([user_embedding, item_embedding], dim=-1)  # the concat latent vector\n",
    "#         print(\"vector\",vector)\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            vector = self.fc_layers[idx](vector)\n",
    "            vector = torch.nn.ReLU()(vector)\n",
    "            # vector = torch.nn.BatchNorm1d()(vector)\n",
    "            # vector = torch.nn.Dropout(p=0.5)(vector)\n",
    "        out = self.affine_output(vector)\n",
    "#         rating = self.logistic(logits)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Matrix Factorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMF(torch.nn.Module):\n",
    "    def __init__(self,  num_users, num_items,latent_dim_mf=8,latent_dim_mlp=8,layers=[16,32,16,8]):\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.latent_dim_mf = latent_dim_mf\n",
    "        self.latent_dim_mlp = latent_dim_mlp\n",
    "\n",
    "        self.embedding_user_mlp = torch.nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.latent_dim_mlp,sparse=True)\n",
    "        self.embedding_item_mlp = torch.nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.latent_dim_mlp,sparse=True)\n",
    "        self.embedding_user_mf = torch.nn.Embedding(num_embeddings=self.num_users, embedding_dim=self.latent_dim_mf,sparse=True)\n",
    "        self.embedding_item_mf = torch.nn.Embedding(num_embeddings=self.num_items, embedding_dim=self.latent_dim_mf,sparse=True)\n",
    "\n",
    "        self.fc_layers = torch.nn.ModuleList()\n",
    "        for idx, (in_size, out_size) in enumerate(zip(layers[:-1], layers[1:])):\n",
    "            self.fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "\n",
    "        self.affine_output = torch.nn.Linear(in_features=layers[-1] + latent_dim_mf, out_features=1)\n",
    "#         self.logistic = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding_mlp = self.embedding_user_mlp(user_indices)\n",
    "        item_embedding_mlp = self.embedding_item_mlp(item_indices)\n",
    "        user_embedding_mf = self.embedding_user_mf(user_indices)\n",
    "        item_embedding_mf = self.embedding_item_mf(item_indices)\n",
    "\n",
    "        mlp_vector = torch.cat([user_embedding_mlp, item_embedding_mlp], dim=-1)  # the concat latent vector\n",
    "        mf_vector =torch.mul(user_embedding_mf, item_embedding_mf)\n",
    "\n",
    "        for idx, _ in enumerate(range(len(self.fc_layers))):\n",
    "            mlp_vector = self.fc_layers[idx](mlp_vector)\n",
    "            mlp_vector = torch.nn.ReLU()(mlp_vector)\n",
    "\n",
    "        vector = torch.cat([mlp_vector, mf_vector], dim=-1)\n",
    "        out = self.affine_output(vector)\n",
    "#         rating = self.logistic(logits)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_eval(model, generator):\n",
    "    model.eval()\n",
    "    y_preds_all = torch.Tensor().to(device) \n",
    "    y_labels_all = torch.Tensor().to(device) \n",
    "    y_pairs_all = torch.Tensor().type(torch.long).to(device) \n",
    "    \n",
    "    for local_batch, local_labels in generator:\n",
    "        local_batch  = torch.tensor(local_batch).type(torch.long).to(device)\n",
    "        local_labels = local_labels.type(torch.float).to(device)\n",
    "        with torch.no_grad():\n",
    "            y_preds = model(local_batch[:,0], local_batch[:,1])\n",
    "        y_preds_all = torch.cat((y_preds_all,y_preds))\n",
    "        y_labels_all = torch.cat((y_labels_all,local_labels))\n",
    "        y_pairs_all = torch.cat((y_pairs_all,local_batch[:,0:2]))\n",
    "        \n",
    "    return y_preds_all, y_labels_all ,y_pairs_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(user_id):\n",
    "    user_rating_pair = [(np.zeros((num_items)) + user_id),np.arange(0,num_items,1)]\n",
    "    local_batch  = torch.tensor(user_rating_pair).type(torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        y_preds = NeuMF_model(local_batch[0], local_batch[1])\n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_run(model, generator, opt, criterion,liveloss,mode=\"train\"):\n",
    "    running_loss = 0\n",
    "    if(mode == \"train\"):\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    i = 0\n",
    "    for local_batch, local_labels  in generator:\n",
    "        local_batch  = torch.tensor(local_batch).type(torch.long).to(device)\n",
    "        local_labels = local_labels.type(torch.float).to(device)\n",
    "        \n",
    "        y_preds = model(local_batch[:,0], local_batch[:,1])\n",
    "        loss = criterion(y_preds, local_labels)\n",
    "\n",
    "        running_loss += (loss.item()*local_labels.size()[0])\n",
    "        if(mode == \"train\"):\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            liveloss.update({\n",
    "                'mse':loss.item()\n",
    "            })\n",
    "            liveloss.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "pre_processed = pre_process_rating(rating_df,50)\n",
    "train_df = pre_processed[\"rating_df\"]\n",
    "num_users = pre_processed[\"num_users\"]\n",
    "num_items = pre_processed[\"num_items\"]\n",
    "train_dataset = pre_processed[\"dataset\"]\n",
    "user_bias = pre_processed[\"user_bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_params = {'batch_size': 1024,'shuffle': True,'num_workers': 0}\n",
    "train_generator = torch.utils.data.DataLoader(train_dataset, **sample_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "NeuMF_model = NeuMF(num_users+1,num_items+1).to(device)\n",
    "NeuMF_opt = optim.SGD(NeuMF_model.parameters(),lr=0.001)\n",
    "NeuMF_criterion = torch.nn.MSELoss()\n",
    "\n",
    "# NeuMF_model.load_state_dict(torch.load(\"./md_checkpoint/neumf_1.pkg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "liveloss1 = PlotLosses()\n",
    "liveloss2 = PlotLosses()\n",
    "liveloss2 = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(NeuMF_model.state_dict(), \"./md_checkpoint/neumf_1.pkg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,10):\n",
    "    epoch_run(NeuMF_model,train_generator,NeuMF_opt,NeuMF_criterion,liveloss1,\"train\")\n",
    "    if i %5:\n",
    "        torch.save(NeuMF_model.state_dict(), \"./md_checkpoint/neumf_\"+i+\".pkg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>314</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>588</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1169</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1185</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id  user_id  rating\n",
       "0        1      314       5\n",
       "1        1      439       3\n",
       "2        1      588       5\n",
       "3        1     1169       4\n",
       "4        1     1185       4"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3.570163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>439</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3.711751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3.536054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3.527329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>439</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3.575893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>439</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>3.856813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18</td>\n",
       "      <td>439</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>4.007541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>439</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>3.984340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>22</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>3.791241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>23</td>\n",
       "      <td>439</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>3.657006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>27</td>\n",
       "      <td>439</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>3.576961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>31</td>\n",
       "      <td>439</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>3.367764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>33</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>3.713231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>35</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>3.794864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>38</td>\n",
       "      <td>439</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>3.681895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>40</td>\n",
       "      <td>439</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3.799331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>45</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>3.517937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>46</td>\n",
       "      <td>439</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>3.530061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>63</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>3.554053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>64</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>3.524895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>67</td>\n",
       "      <td>439</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>3.811730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>75</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>3.765348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>76</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>3.432030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>78</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>3.413211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>80</td>\n",
       "      <td>439</td>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>3.559883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>81</td>\n",
       "      <td>439</td>\n",
       "      <td>2</td>\n",
       "      <td>81</td>\n",
       "      <td>3.743515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>86</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>3.325279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>87</td>\n",
       "      <td>439</td>\n",
       "      <td>5</td>\n",
       "      <td>87</td>\n",
       "      <td>4.117615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>93</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>93</td>\n",
       "      <td>3.823999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>94</td>\n",
       "      <td>439</td>\n",
       "      <td>5</td>\n",
       "      <td>94</td>\n",
       "      <td>3.703095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2408</td>\n",
       "      <td>439</td>\n",
       "      <td>4</td>\n",
       "      <td>2408</td>\n",
       "      <td>3.310071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2462</td>\n",
       "      <td>439</td>\n",
       "      <td>4</td>\n",
       "      <td>2462</td>\n",
       "      <td>3.631748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2738</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>2738</td>\n",
       "      <td>3.712832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2827</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>2827</td>\n",
       "      <td>3.373246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>3029</td>\n",
       "      <td>439</td>\n",
       "      <td>2</td>\n",
       "      <td>3029</td>\n",
       "      <td>3.740150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>3123</td>\n",
       "      <td>439</td>\n",
       "      <td>4</td>\n",
       "      <td>3123</td>\n",
       "      <td>3.602133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>3197</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>3197</td>\n",
       "      <td>3.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>3250</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>3250</td>\n",
       "      <td>3.344128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>3385</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>3385</td>\n",
       "      <td>3.327921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>3533</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>3533</td>\n",
       "      <td>3.688791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>3979</td>\n",
       "      <td>439</td>\n",
       "      <td>2</td>\n",
       "      <td>3979</td>\n",
       "      <td>3.797946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>3997</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>3997</td>\n",
       "      <td>3.743051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>4027</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>4027</td>\n",
       "      <td>3.672449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>4108</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>4108</td>\n",
       "      <td>3.517279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>4130</td>\n",
       "      <td>439</td>\n",
       "      <td>2</td>\n",
       "      <td>4130</td>\n",
       "      <td>3.688970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>4253</td>\n",
       "      <td>439</td>\n",
       "      <td>4</td>\n",
       "      <td>4253</td>\n",
       "      <td>3.520154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>4473</td>\n",
       "      <td>439</td>\n",
       "      <td>2</td>\n",
       "      <td>4473</td>\n",
       "      <td>3.734778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>5343</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>5343</td>\n",
       "      <td>3.544146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>5932</td>\n",
       "      <td>439</td>\n",
       "      <td>4</td>\n",
       "      <td>5932</td>\n",
       "      <td>3.620789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>6276</td>\n",
       "      <td>439</td>\n",
       "      <td>4</td>\n",
       "      <td>6276</td>\n",
       "      <td>3.877519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>6333</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>6333</td>\n",
       "      <td>3.601777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>6533</td>\n",
       "      <td>439</td>\n",
       "      <td>2</td>\n",
       "      <td>6533</td>\n",
       "      <td>3.703715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>6975</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>6975</td>\n",
       "      <td>3.335433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>7277</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>7277</td>\n",
       "      <td>3.863475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>7326</td>\n",
       "      <td>439</td>\n",
       "      <td>4</td>\n",
       "      <td>7326</td>\n",
       "      <td>3.799853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>7796</td>\n",
       "      <td>439</td>\n",
       "      <td>2</td>\n",
       "      <td>7796</td>\n",
       "      <td>3.730752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>8007</td>\n",
       "      <td>439</td>\n",
       "      <td>1</td>\n",
       "      <td>8007</td>\n",
       "      <td>3.446948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>9628</td>\n",
       "      <td>439</td>\n",
       "      <td>2</td>\n",
       "      <td>9628</td>\n",
       "      <td>3.436206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>9663</td>\n",
       "      <td>439</td>\n",
       "      <td>2</td>\n",
       "      <td>9663</td>\n",
       "      <td>3.582057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>9691</td>\n",
       "      <td>439</td>\n",
       "      <td>3</td>\n",
       "      <td>9691</td>\n",
       "      <td>3.745519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     book_id  user_id  rating  index         0\n",
       "0          1      439       3      1  3.570163\n",
       "1          4      439       5      4  3.711751\n",
       "2          7      439       3      7  3.536054\n",
       "3          9      439       3      9  3.527329\n",
       "4         11      439       4     11  3.575893\n",
       "5         17      439       5     17  3.856813\n",
       "6         18      439       4     18  4.007541\n",
       "7         20      439       5     20  3.984340\n",
       "8         22      439       3     22  3.791241\n",
       "9         23      439       2     23  3.657006\n",
       "10        27      439       5     27  3.576961\n",
       "11        31      439       4     31  3.367764\n",
       "12        33      439       3     33  3.713231\n",
       "13        35      439       3     35  3.794864\n",
       "14        38      439       4     38  3.681895\n",
       "15        40      439       1     40  3.799331\n",
       "16        45      439       3     45  3.517937\n",
       "17        46      439       4     46  3.530061\n",
       "18        63      439       3     63  3.554053\n",
       "19        64      439       3     64  3.524895\n",
       "20        67      439       4     67  3.811730\n",
       "21        75      439       3     75  3.765348\n",
       "22        76      439       3     76  3.432030\n",
       "23        78      439       3     78  3.413211\n",
       "24        80      439       4     80  3.559883\n",
       "25        81      439       2     81  3.743515\n",
       "26        86      439       3     86  3.325279\n",
       "27        87      439       5     87  4.117615\n",
       "28        93      439       3     93  3.823999\n",
       "29        94      439       5     94  3.703095\n",
       "..       ...      ...     ...    ...       ...\n",
       "147     2408      439       4   2408  3.310071\n",
       "148     2462      439       4   2462  3.631748\n",
       "149     2738      439       3   2738  3.712832\n",
       "150     2827      439       3   2827  3.373246\n",
       "151     3029      439       2   3029  3.740150\n",
       "152     3123      439       4   3123  3.602133\n",
       "153     3197      439       3   3197  3.810811\n",
       "154     3250      439       3   3250  3.344128\n",
       "155     3385      439       3   3385  3.327921\n",
       "156     3533      439       3   3533  3.688791\n",
       "157     3979      439       2   3979  3.797946\n",
       "158     3997      439       3   3997  3.743051\n",
       "159     4027      439       3   4027  3.672449\n",
       "160     4108      439       3   4108  3.517279\n",
       "161     4130      439       2   4130  3.688970\n",
       "162     4253      439       4   4253  3.520154\n",
       "163     4473      439       2   4473  3.734778\n",
       "164     5343      439       3   5343  3.544146\n",
       "165     5932      439       4   5932  3.620789\n",
       "166     6276      439       4   6276  3.877519\n",
       "167     6333      439       3   6333  3.601777\n",
       "168     6533      439       2   6533  3.703715\n",
       "169     6975      439       3   6975  3.335433\n",
       "170     7277      439       3   7277  3.863475\n",
       "171     7326      439       4   7326  3.799853\n",
       "172     7796      439       2   7796  3.730752\n",
       "173     8007      439       1   8007  3.446948\n",
       "174     9628      439       2   9628  3.436206\n",
       "175     9663      439       2   9663  3.582057\n",
       "176     9691      439       3   9691  3.745519\n",
       "\n",
       "[177 rows x 5 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show result contrast\n",
    "USERID = 439\n",
    "predict_y = predict(USERID-user_bias)\n",
    "predict_df = pd.DataFrame(predict_y.numpy()).reset_index()\n",
    "rating_df[rating_df['user_id']==USERID].merge(predict_df,left_on=\"book_id\",right_on=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "186px",
    "width": "273px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "197.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
